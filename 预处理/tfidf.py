# -*- coding: utf-8 -*-
"""
Created on Mon Apr  1 19:44:43 2019

@author: Administrator
"""

from gensim import corpora, models, similarities
import jieba
import numpy as np
from math import *
import csv
sentences = ["中国视频工作驾驶一线发布民警交警检察官好人全国公安转发文明老人国家孩子时代交通安全活动高速发展微博走近检察一路平安微观群众男子公益司机建设时间检察机关现场习近平车辆报告案件精神服务平安生活检察院中央十九情况"]
words=[]
words2=[]
for doc in sentences:
    words.append(list(jieba.cut(doc)))
print(words)
dic = corpora.Dictionary(words)
dic2={'中国': 0, '宣传': 1, '一线': 2, '成功': 3, '汽车': 4, '加油': 5, '对话': 6, '建设': 7, '宪法': 8, '这是': 9, '时代': 10, '妈妈': 11, '关注': 12, '转发': 13, '文章': 14, '手机': 15, '有人': 16, '参加': 17, '头条': 18, '爱心': 19, '受伤': 20, '成长': 21, '人生': 22, '幸福': 23, '高速公路': 24, '平台': 25, '微博': 26, '网络': 27, '开车': 28, '扶贫': 29, '系统': 30, '故事': 31, '法律': 32, '央视': 33, '温暖': 34, '生命': 35, '正确': 36, '平安': 37, '部长': 38, '核心': 39, '文化': 40, '音乐': 41, '网上': 42, '总书记': 43, '高速': 44, '话筒': 45, '健康': 46, '改革开放': 47, '周年': 48, '社会': 49, '我国': 50, '生活': 51, '交警': 52, '老人': 53, '美丽': 54, '历史': 55, '青年': 56, '出行': 57, '路上': 58, '共青团中央': 59, '力量': 60, '选择': 61, '发布': 62, '一带': 63, '告诉': 64, '学习': 65, '参与': 66, '经验': 67, '能量': 68, '特色': 69, '努力': 70, '危险': 71, '致敬': 72, '预防': 73, '车辆': 74, '精神': 75, '公益': 76, '孩子': 77, '湖北': 78, '知识': 79, '父亲': 80, '报告': 81, '一路': 82, '主题': 83, '一位': 84, '点赞': 85, '故宫': 86, '面对': 87, '故宫博物院': 88, '文明': 89, '志愿者': 90, '简单': 91, '这位': 92, '保护': 93, '守护': 94, '身边': 95, '思想': 96, '案例': 97, '专家': 98, '习惯': 99, '老师': 100, '提示': 101, '小心': 102, '最终': 103, '过程': 104, '五年': 105, '导致': 106, '公安部': 107, '贯彻': 108, '十九': 109, '英雄': 110, '司机': 111, '驾驶': 112, '犯罪': 113, '梦想': 114, '儿童': 115, '好人': 116, '最高人民法院': 117, '最高人民检察院': 118, '公安机关': 119, '群众': 120, '权威': 121, '民警': 122, '儿子': 123, '心声': 124, '检察官': 125, '家庭': 126, '来到': 127, '网秒': 128, '执勤': 129, '牺牲': 130, '停车': 131, '大队': 132, '最美': 133, '维护': 134, '法治': 135, '年前': 136, '村民': 137, '希望': 138, '处罚': 139, '感受': 140, '一年': 141, '轿车': 142, '蜡烛': 143, '办案': 144, '分钟': 145, '一路平安': 146, '祖国': 147, '路口': 148, '行驶': 149, '奋斗': 150, '引发': 151, '人民日报': 152, '传递': 153, '乘客': 154, '事故': 155, '回头': 156, '驾车': 157, '罚款': 158, '医生': 159, '小朋友': 160, '监督': 161, '女孩': 162, '教育': 163, '志愿': 164, '少年': 165, '邪教': 166, '手绘': 167, '价值观': 168, '检察': 169, '家乡': 170, '交通事故': 171, '公交车': 172, '行车': 173, '最高检': 174, '普法': 175, '司法': 176, '建议': 177, '货车': 178, '交通安全': 179, '车主': 180, '照顾': 181, '感动': 182, '这座': 183, '民事': 184, '倒车': 185, '机动车': 186, '覆车之戒': 187, '酒驾': 188, '扫黑': 189, '除恶': 190, '走近': 191, '爱上': 192, '驾驶证': 193, '王俊凯': 194, '画时代': 195, '微观': 196}
#for word,index in dic2.items():
 #   print (word +" 编号为:"+ str(index))

corpus = [dic.doc2bow(text) for text in words]
vector_a=[0.082289458, 0.006798159, 0.028923242, 0.005274238, 0.00759944, 0.005974334, 0.004253418, 0.011846316, 0.003454014, 0.00482054, 0.01797778, 0.004707116, 0.00986793, 0.021153665, 0.005138813, 0.005787926, 0.004593691, 0.003629583, 0.004933965, 0.004026569, 0.004593691, 0.003678308, 0.004536979, 0.005614512, 0.004423555, 0.005217526, 0.013781074, 0.008179492, 0.006446898, 0.006635332, 0.004760163, 0.009697793, 0.008053138, 0.007194338, 0.005954785, 0.009981354, 0.003343893, 0.010619022, 0.004074803, 0.006011497, 0.008005729, 0.003459447, 0.003534973, 0.008903821, 0.013861181, 0.005827928, 0.004480267, 0.008506836, 0.005057312, 0.008410812, 0.005896111, 0.010548476, 0.02456269, 0.019905996, 0.004074803, 0.006425651, 0.00986793, 0.004002865, 0.004381514, 0.00421659, 0.007052544, 0.003840586, 0.027857774, 0.005485312, 0.003604634, 0.008038466, 0.004976534, 0.003913144, 0.00533095, 0.00421659, 0.009017246, 0.006707503, 0.007079642, 0.003743008, 0.011115599, 0.010775325, 0.012136419, 0.018607911, 0.008563548, 0.004990677, 0.003407844, 0.010945462, 0.008223275, 0.004922442, 0.00976908, 0.00371549, 0.008790397, 0.004366842, 0.00328931, 0.020150536, 0.003395669, 0.00379972, 0.003894679, 0.009682605, 0.00606821, 0.006477893, 0.005224107, 0.005301091, 0.003624215, 0.003686296, 0.003913144, 0.004083281, 0.003346022, 0.005217526, 0.004543792, 0.003324647, 0.004423555, 0.022968457, 0.003459447, 0.010321627, 0.008960534, 0.012079707, 0.030454472, 0.006124922, 0.005444375, 0.006805469, 0.024386263, 0.00862026, 0.004480267, 0.004139993, 0.012224965, 0.004593691, 0.02761886, 0.004877253, 0.003821592, 0.024501061, 0.003516159, 0.006635332, 0.003516159, 0.006862181, 0.004388327, 0.005387663, 0.007004278, 0.004536979, 0.004536979, 0.004933965, 0.004763828, 0.00482054, 0.00759944, 0.004165143, 0.00342389, 0.00431013, 0.003732401, 0.00508472, 0.00605839, 0.004026569, 0.01285298, 0.00482054, 0.003374269, 0.003674901, 0.006328854, 0.003358448, 0.006295058, 0.003948772, 0.006295058, 0.009470944, 0.004423555, 0.005444375, 0.004026569, 0.004877253, 0.003402734, 0.00986793, 0.00482054, 0.006238346, 0.003402734, 0.004366842, 0.004083281, 0.003656875, 0.007789358, 0.013036356, 0.003744356, 0.005217526, 0.004026569, 0.006692044, 0.009641081, 0.003743008, 0.008654842, 0.005274238, 0.004593691, 0.016956959, 0.003352951, 0.003459447, 0.004650404, 0.004763828, 0.004593691, 0.00328931, 0.005444375, 0.003969728, 0.003403754, 0.004083281, 0.003894679, 0.013043815, 0.003516159, 0.006465195, 0.004327421, 0.003291187, 0.012476692]
tests=[]
with open(r"C:\Users\Administrator\Desktop\text-cnn-master\text-cnn-master\data\test.txt","r",encoding="utf-8")as f:
 #   cos_score=[]
    score=[]  
    for line in f:
        tests.append(line.split("	")[2])
    for i in range( 0,len(tests)):
        words2=list(jieba.cut(tests[i]))
        counter=[]
        for word in dic2:    
            if word in words2 :               
                counter.append(vector_a[dic2[word]])

            else:
                counter.append(0)
        m=0
        for i in counter:
            m=m+i
        vector_b=counter
        score.append(m)
       
 #       num=sum([a*b for a,b in zip(vector_a,vector_b)])
 #       denom=np.linalg.norm(vector_a)*np.linalg.norm(vector_b)
 #       cos=num/denom
 #       cos_score.append(cos)
      
with open (r'C:\Users\Administrator\Desktop\毕设代码\score.csv',"w",encoding='gbk',newline='')as f2:
    file=csv.writer(f2)
    for score in score:
        file.writerow(["%.3f " %score])
       
            
       


#lda = models.LdaModel(corpus_tfidf, id2word=dic, num_topics=2)
#ldaOut=lda.print_topics(2)
#print(ldaOut[0])
#print(ldaOut[1])
#corpus_lda = lda[corpus_tfidf]
#for doc in corpus_lda:
#	print(doc)

